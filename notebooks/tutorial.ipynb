{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0027888",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/apdcephfs/private_chewu/PALM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aeb0752",
   "metadata": {},
   "source": [
    "Load PALM from torch.hub (PyTorch >= 1.1):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604e786f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from palm.models.palm import PALMModel\n",
    "# hubconf.py\n",
    "palm = torch.hub.load('../','palm.base',source='local')\n",
    "palm.eval()  # disable dropout (or leave in train mode to finetune)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5d4c1a",
   "metadata": {},
   "source": [
    "Load PALM (for PyTorch 1.0 or custom models):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55e4ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from palm.models.palm import PALMModel\n",
    "palm = PALMModel.from_pretrained('/apdcephfs/share_1351585/FM/NLG/zh/palm_pretrain_checkpoints/', checkpoint_file='checkpoint_best.pt')\n",
    "palm.eval()  # disable dropout (or leave in train mode to finetune)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4cc0ac2",
   "metadata": {},
   "source": [
    "Apply Byte-Pair Encoding (BPE) to input text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0bce76",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = palm.encode(['22日，国家航天局公布祝融号火星车携带的前避障相机和后避障相机拍摄的驶离过程影像。',\n",
    "                       '上海：6月1日至中下旬全面恢复正常生产生活秩序。'])\n",
    "# assert tokens.tolist() == [0, 31414, 232, 328, 2]\n",
    "print(inputs)\n",
    "# palm.decode(tokens)  # 'Hello world!'\n",
    "palm.model.encoder(src_tokens=inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b230d4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = palm.encode(['打破200年军事不结盟传统！瑞典执政党决定支持该国加入北约。',\n",
    "                       '金正恩亲自前往药店了解情况 下令投入军医稳定平壤供药'])\n",
    "# assert tokens.tolist() == [0, 31414, 232, 328, 2]\n",
    "print(inputs)\n",
    "# palm.decode(tokens)  # 'Hello world!'\n",
    "palm.model.encoder(src_tokens=inputs['net_input']['src_tokens'], src_lengths=inputs['net_input']['src_lengths'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8c9dd8",
   "metadata": {},
   "source": [
    "Extract features from PALM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e429e16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the last layer's features\n",
    "last_layer_features = palm.extract_features(tokens)\n",
    "assert last_layer_features.size() == torch.Size([1, 5, 1024])\n",
    "\n",
    "# Extract all layer's features from decoder (layer 0 is the embedding layer)\n",
    "all_layers = palm.extract_features(tokens, return_all_hiddens=True)\n",
    "assert len(all_layers) == 13\n",
    "assert torch.all(all_layers[-1] == last_layer_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d8bff9",
   "metadata": {},
   "source": [
    "Use PALM for sentence-pair classification tasks:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb02907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download PALM already finetuned for MNLI\n",
    "palm = torch.hub.load('pytorch/fairseq', 'palm.large.mnli')\n",
    "palm.eval()  # disable dropout for evaluation\n",
    "\n",
    "# Encode a pair of sentences and make a prediction\n",
    "tokens = palm.encode('PALM is a seq2seq model.', 'PALM is not sequence to sequence.')\n",
    "palm.predict('mnli', tokens).argmax()  # 0: contradiction\n",
    "\n",
    "# Encode another pair of sentences\n",
    "tokens = palm.encode('PALM is denoising autoencoder.', 'PALM is version of autoencoder.')\n",
    "palm.predict('mnli', tokens).argmax()  # 2: entailment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fff3d81",
   "metadata": {},
   "source": [
    "Register a new (randomly initialized) classification head:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2a0eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "palm.register_classification_head('new_task', num_classes=3)\n",
    "logprobs = palm.predict('new_task', tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4cfc03",
   "metadata": {},
   "source": [
    "Batched prediction:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4133dcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from fairseq.data.data_utils import collate_tokens\n",
    "\n",
    "palm = torch.hub.load('pytorch/fairseq', 'palm.large.mnli')\n",
    "palm.eval()\n",
    "\n",
    "batch_of_pairs = [\n",
    "    ['PALM is a seq2seq model.', 'PALM is not sequence to sequence.'],\n",
    "    ['PALM is denoising autoencoder.', 'PALM is version of autoencoder.'],\n",
    "]\n",
    "\n",
    "batch = collate_tokens(\n",
    "    [palm.encode(pair[0], pair[1]) for pair in batch_of_pairs], pad_idx=1\n",
    ")\n",
    "\n",
    "logprobs = palm.predict('mnli', batch)\n",
    "print(logprobs.argmax(dim=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7923b049",
   "metadata": {},
   "source": [
    "Using the GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b67b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "palm.cuda()\n",
    "palm.predict('new_task', tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098397a3",
   "metadata": {},
   "source": [
    "Filling masks:\n",
    "\n",
    "PALM can be used to fill multiple <mask> tokens in the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee78417",
   "metadata": {},
   "outputs": [],
   "source": [
    "palm = torch.hub.load('pytorch/fairseq', 'palm.base')\n",
    "palm.eval()\n",
    "palm.fill_mask(['The cat <mask> on the <mask>.'], topk=3, beam=10)\n",
    "# [[('The cat was on the ground.', tensor(-0.6183)), ('The cat was on the floor.', tensor(-0.6798)), ('The cat sleeps on the couch.', tensor(-0.6830))]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
